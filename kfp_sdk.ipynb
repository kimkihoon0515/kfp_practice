{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263158f8-d7ef-4382-91ae-4a1844e424ca",
   "metadata": {},
   "source": [
    "# Client 동기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7436d5e-fe19-4509-b2de-fdf5f2fc776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Demo] XGBoost - Iterative model training\n",
      "[Demo] TFX - Taxi tip prediction model trainer\n",
      "[Tutorial] Data passing in python components\n",
      "[Tutorial] DSL - Control structures\n",
      "test\n",
      "http://172.17.0.43:8080/dex/auth/local/login?back=&state=lz3bmbe26klpjm4ojdiw3cwox\n",
      "MTY3MjU2MTQ4MnxOd3dBTkZCSFNFUllWemMwVkVKWVNWTlFVRE5NU0ZGSFVraEJVa0kwUXpaV1VsWmFRVWROVmtzeU1sVlVUVUpVVEVKRldFNURSMEU9fKARRzeW8z0wvE1Epj06MrlF_VAD-W1CN7kbJb4yG4p4\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import requests\n",
    "\n",
    "USERNAME = \"user@example.com\"\n",
    "PASSWORD = \"12341234\"\n",
    "NAMESPACE = \"kubeflow-user-example-com\"\n",
    "HOST = \"http://172.17.0.43:8080\" # istio-ingressgateway pod ip:port\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.get(HOST)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "}\n",
    "\n",
    "data = {\"login\": \"user@example.com\", \"password\": \"12341234\"}\n",
    "session.post(response.url, headers=headers, data=data)\n",
    "session_cookie = session.cookies.get_dict()[\"authservice_session\"]\n",
    "\n",
    "client = kfp.Client(\n",
    "    host=f\"{HOST}/pipeline\",\n",
    "    namespace=f\"{NAMESPACE}\",\n",
    "    cookies=f\"authservice_session={session_cookie}\",\n",
    ")\n",
    "list_pipelines = client.list_pipelines()\n",
    "\n",
    "for i in range(list_pipelines.total_size):\n",
    "    print(list_pipelines.pipelines[i].name)\n",
    "print(response.url)\n",
    "print(session_cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baae55e2-c478-4428-ae7c-99a77175b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kfp._client.Client at 0x7f480eae8a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610e44f-987e-40aa-b891-5d80c5150e63",
   "metadata": {},
   "source": [
    "# Experiment 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06776e58-197a-42dd-bdb8-7143f0ce1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = client.get_experiment(experiment_name=\"mnist-pipeline\",namespace=NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e57a984-fa76-44bb-8762-d98910608396",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = experiment_info.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fbd226-b893-4604-923d-d946277645dd",
   "metadata": {},
   "source": [
    "# Experiment 삭제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73b36a58-5a0f-4d11-8eb1-1ccc5df3ca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc04cd1-dfca-45c1-8c36-72384c3dcc1b",
   "metadata": {},
   "source": [
    "# Runs 삭제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e250abb2-d2d1-44bb-abec-7d6b9a7bba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6d768f1f-e224-4bd0-87d0-4d871bbc8c85\n"
     ]
    }
   ],
   "source": [
    "for i in range(client.list_runs().total_size):\n",
    "    run_id = client.list_runs().runs[i].id\n",
    "    client.runs.delete_run(id=run_id)\n",
    "    print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594aae4-6ae0-48ba-8fe4-0081e94adf8d",
   "metadata": {},
   "source": [
    "## Pipeline Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9411a88b-fb8b-4529-90b0-6fdbc7fe19b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=http://172.17.0.43:8080/pipeline/#/pipelines/details/9eb7b704-8b2e-4696-ade3-54b12ea65538>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 1, 1, 9, 26, 28, tzinfo=tzlocal()),\n",
       " 'default_version': {'code_source_url': None,\n",
       "                     'created_at': datetime.datetime(2023, 1, 1, 9, 26, 28, tzinfo=tzlocal()),\n",
       "                     'id': '9eb7b704-8b2e-4696-ade3-54b12ea65538',\n",
       "                     'name': 'mnist-pipeline',\n",
       "                     'package_url': None,\n",
       "                     'parameters': [{'name': 'no_epochs', 'value': None},\n",
       "                                    {'name': 'optimizer', 'value': None}],\n",
       "                     'resource_references': [{'key': {'id': '9eb7b704-8b2e-4696-ade3-54b12ea65538',\n",
       "                                                      'type': 'PIPELINE'},\n",
       "                                              'name': None,\n",
       "                                              'relationship': 'OWNER'}]},\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'id': '9eb7b704-8b2e-4696-ade3-54b12ea65538',\n",
       " 'name': 'mnist-pipeline',\n",
       " 'parameters': [{'name': 'no_epochs', 'value': None},\n",
       "                {'name': 'optimizer', 'value': None}],\n",
       " 'resource_references': None,\n",
       " 'url': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_package_path='/home/jovyan/output_test.yaml'\n",
    "pipeline_name='mnist-pipeline'\n",
    "client.upload_pipeline(pipeline_package_path=pipeline_package_path,pipeline_name=pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e7bde-452b-4df3-9e45-597d05fb7a44",
   "metadata": {},
   "source": [
    "# Experiment 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45150325-3463-4273-8d04-72f1e125c38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://172.17.0.43:8080/pipeline/#/experiments/details/a536241d-4a75-44e7-8060-3b72d615ce88\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = client.create_experiment(name=pipeline_name,description=pipeline_name,namespace=NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1725b41-9866-4760-aef2-3dfef09689cc",
   "metadata": {},
   "source": [
    "## Run 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b639a024-05a0-4ba8-8c0b-c8c70f0c8b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://172.17.0.43:8080/pipeline/#/runs/details/775d2774-637e-4801-9e3f-4d78aeec0d40\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 1, 1, 9, 26, 31, tzinfo=tzlocal()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'id': '775d2774-637e-4801-9e3f-4d78aeec0d40',\n",
       " 'metrics': None,\n",
       " 'name': 'mnist-pipeline',\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': None,\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': None,\n",
       "                   'workflow_manifest': '{\"apiVersion\": '\n",
       "                                        '\"argoproj.io/v1alpha1\", \"kind\": '\n",
       "                                        '\"Workflow\", \"metadata\": '\n",
       "                                        '{\"generateName\": '\n",
       "                                        '\"digits-recognizer-pipeline-\", '\n",
       "                                        '\"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline_compilation_time\": '\n",
       "                                        '\"2023-01-01T09:25:42.458223\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline_spec\": '\n",
       "                                        '\"{\\\\\"description\\\\\": \\\\\"Detect '\n",
       "                                        'digits\\\\\", \\\\\"inputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"no_epochs\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"optimizer\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"digits-recognizer-pipeline\\\\\"}\"}, '\n",
       "                                        '\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\"}}, \"spec\": {\"entrypoint\": '\n",
       "                                        '\"digits-recognizer-pipeline\", '\n",
       "                                        '\"templates\": [{\"name\": '\n",
       "                                        '\"digits-recognizer-pipeline\", \"dag\": '\n",
       "                                        '{\"tasks\": [{\"name\": \"get-data-batch\", '\n",
       "                                        '\"template\": \"get-data-batch\"}, '\n",
       "                                        '{\"name\": \"get-latest-data\", '\n",
       "                                        '\"template\": \"get-latest-data\"}, '\n",
       "                                        '{\"name\": \"model-building\", '\n",
       "                                        '\"template\": \"model-building\", '\n",
       "                                        '\"dependencies\": [\"reshape-data\"]}, '\n",
       "                                        '{\"name\": \"reshape-data\", \"template\": '\n",
       "                                        '\"reshape-data\", \"dependencies\": '\n",
       "                                        '[\"get-data-batch\", '\n",
       "                                        '\"get-latest-data\"]}]}}, {\"name\": '\n",
       "                                        '\"get-data-batch\", \"container\": '\n",
       "                                        '{\"args\": [\"----output-paths\", '\n",
       "                                        '\"/tmp/outputs/datapoints_training/data\", '\n",
       "                                        '\"/tmp/outputs/datapoints_test/data\", '\n",
       "                                        '\"/tmp/outputs/dataset_version/data\"], '\n",
       "                                        '\"command\": [\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def get_data_batch():\\\\n    '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n    Function to get '\n",
       "                                        'dataset and load it to minio '\n",
       "                                        'bucket\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    '\n",
       "                                        'print(\\\\\"getting data\\\\\")\\\\n    from '\n",
       "                                        'tensorflow import keras\\\\n    from '\n",
       "                                        'minio import Minio\\\\n    import numpy '\n",
       "                                        'as np\\\\n    import json\\\\n    import '\n",
       "                                        'os\\\\n\\\\n    minio_client = '\n",
       "                                        'Minio(\\\\n        '\n",
       "                                        '\\\\\"172.17.0.15:9000\\\\\",\\\\n        '\n",
       "                                        'access_key=\\\\\"minio\\\\\",\\\\n        '\n",
       "                                        'secret_key=\\\\\"minio123\\\\\",\\\\n        '\n",
       "                                        'secure=False\\\\n    )\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\"mlpipeline\\\\\"\\\\n\\\\n    if not '\n",
       "                                        'os.path.exists(\\\\\"./tmp\\\\\"):\\\\n        '\n",
       "                                        'os.makedirs(\\\\\"./tmp\\\\\")\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"mnist.npz\\\\\",\\\\\"./tmp/mnist.npz\\\\\")\\\\n\\\\n    '\n",
       "                                        'def load_data():\\\\n        with '\n",
       "                                        'np.load(\\\\\"./tmp/mnist.npz\\\\\", '\n",
       "                                        'allow_pickle=True) as '\n",
       "                                        'f:\\\\n            x_train, y_train = '\n",
       "                                        'f[\\\\\"x_train\\\\\"], '\n",
       "                                        'f[\\\\\"y_train\\\\\"]\\\\n            '\n",
       "                                        'x_test, y_test = f[\\\\\"x_test\\\\\"], '\n",
       "                                        'f[\\\\\"y_test\\\\\"]\\\\n\\\\n        return '\n",
       "                                        '(x_train, y_train), (x_test, '\n",
       "                                        'y_test)\\\\n\\\\n    # Get MNIST data '\n",
       "                                        'directly from library\\\\n    (x_train, '\n",
       "                                        'y_train), (x_test, y_test) = '\n",
       "                                        'load_data()\\\\n\\\\n    # save to numpy '\n",
       "                                        'file, store in Minio\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/x_train.npy\\\\\",x_train)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"x_train\\\\\",\\\\\"./tmp/x_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/y_train.npy\\\\\",y_train)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"y_train\\\\\",\\\\\"./tmp/y_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/x_test.npy\\\\\",x_test)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"x_test\\\\\",\\\\\"./tmp/x_test.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/y_test.npy\\\\\",y_test)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"y_test\\\\\",\\\\\"./tmp/y_test.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'dataset_version = \\\\\"1.0\\\\\"\\\\n\\\\n    '\n",
       "                                        'print(f\\\\\"x_train shape: '\n",
       "                                        '{x_train.shape}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"y_train shape: '\n",
       "                                        '{y_train.shape}\\\\\")\\\\n\\\\n    '\n",
       "                                        'print(f\\\\\"x_test shape: '\n",
       "                                        '{x_test.shape}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"y_test shape: '\n",
       "                                        '{y_test.shape}\\\\\")\\\\n\\\\n    from '\n",
       "                                        'collections import namedtuple\\\\n    '\n",
       "                                        \"divmod_output = namedtuple('Outputs', \"\n",
       "                                        \"['datapoints_training', \"\n",
       "                                        \"'datapoints_test', \"\n",
       "                                        \"'dataset_version'])\\\\n    return \"\n",
       "                                        '[float(x_train.shape[0]),float(x_test.shape[0]),dataset_version]\\\\n\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-> str:\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\n        return '\n",
       "                                        'float_value\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\"{}\\\\\" has type '\n",
       "                                        '\\\\\"{}\\\\\" instead of '\n",
       "                                        \"float.'.format(str(float_value), \"\n",
       "                                        'str(type(float_value))))\\\\n    return '\n",
       "                                        'str(float_value)\\\\n\\\\ndef '\n",
       "                                        '_serialize_str(str_value: str) -> '\n",
       "                                        'str:\\\\n    if not '\n",
       "                                        'isinstance(str_value, str):\\\\n        '\n",
       "                                        'raise TypeError(\\'Value \\\\\"{}\\\\\" has '\n",
       "                                        'type \\\\\"{}\\\\\" instead of '\n",
       "                                        \"str.'.format(str(str_value), \"\n",
       "                                        'str(type(str_value))))\\\\n    return '\n",
       "                                        'str_value\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Get \"\n",
       "                                        \"data batch', description='Function to \"\n",
       "                                        'get dataset and load it to minio '\n",
       "                                        'bucket\\')\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=3)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'get_data_batch(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    _serialize_float,\\\\n    '\n",
       "                                        '_serialize_float,\\\\n    '\n",
       "                                        '_serialize_str,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\"}, '\n",
       "                                        '\"outputs\": {\"artifacts\": [{\"name\": '\n",
       "                                        '\"get-data-batch-datapoints_test\", '\n",
       "                                        '\"path\": '\n",
       "                                        '\"/tmp/outputs/datapoints_test/data\"}, '\n",
       "                                        '{\"name\": '\n",
       "                                        '\"get-data-batch-datapoints_training\", '\n",
       "                                        '\"path\": '\n",
       "                                        '\"/tmp/outputs/datapoints_training/data\"}, '\n",
       "                                        '{\"name\": '\n",
       "                                        '\"get-data-batch-dataset_version\", '\n",
       "                                        '\"path\": '\n",
       "                                        '\"/tmp/outputs/dataset_version/data\"}]}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"description\\\\\": \\\\\"Function to '\n",
       "                                        'get dataset and load it to minio '\n",
       "                                        'bucket\\\\\", \\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"datapoints_training\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"datapoints_test\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"dataset_version\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'get_data_batch():\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'Function to get dataset and load it '\n",
       "                                        'to minio bucket\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'print(\\\\\\\\\\\\\"getting '\n",
       "                                        'data\\\\\\\\\\\\\")\\\\\\\\n    from tensorflow '\n",
       "                                        'import keras\\\\\\\\n    from minio '\n",
       "                                        'import Minio\\\\\\\\n    import numpy as '\n",
       "                                        'np\\\\\\\\n    import json\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n\\\\\\\\n    minio_client = '\n",
       "                                        'Minio(\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"172.17.0.15:9000\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'access_key=\\\\\\\\\\\\\"minio\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secret_key=\\\\\\\\\\\\\"minio123\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secure=False\\\\\\\\n    )\\\\\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\\\\\\\\\"mlpipeline\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'if not '\n",
       "                                        'os.path.exists(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\"):\\\\\\\\n        '\n",
       "                                        'os.makedirs(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"mnist.npz\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/mnist.npz\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def load_data():\\\\\\\\n        with '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/mnist.npz\\\\\\\\\\\\\", '\n",
       "                                        'allow_pickle=True) as '\n",
       "                                        'f:\\\\\\\\n            x_train, y_train = '\n",
       "                                        'f[\\\\\\\\\\\\\"x_train\\\\\\\\\\\\\"], '\n",
       "                                        'f[\\\\\\\\\\\\\"y_train\\\\\\\\\\\\\"]\\\\\\\\n            '\n",
       "                                        'x_test, y_test = '\n",
       "                                        'f[\\\\\\\\\\\\\"x_test\\\\\\\\\\\\\"], '\n",
       "                                        'f[\\\\\\\\\\\\\"y_test\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'return (x_train, y_train), (x_test, '\n",
       "                                        'y_test)\\\\\\\\n\\\\\\\\n    # Get MNIST data '\n",
       "                                        'directly from library\\\\\\\\n    '\n",
       "                                        '(x_train, y_train), (x_test, y_test) '\n",
       "                                        '= load_data()\\\\\\\\n\\\\\\\\n    # save to '\n",
       "                                        'numpy file, store in Minio\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\",x_train)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"x_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/y_train.npy\\\\\\\\\\\\\",y_train)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"y_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/y_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\",x_test)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"x_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/y_test.npy\\\\\\\\\\\\\",y_test)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"y_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/y_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'dataset_version = '\n",
       "                                        '\\\\\\\\\\\\\"1.0\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'print(f\\\\\\\\\\\\\"x_train shape: '\n",
       "                                        '{x_train.shape}\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'print(f\\\\\\\\\\\\\"y_train shape: '\n",
       "                                        '{y_train.shape}\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'print(f\\\\\\\\\\\\\"x_test shape: '\n",
       "                                        '{x_test.shape}\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'print(f\\\\\\\\\\\\\"y_test shape: '\n",
       "                                        '{y_test.shape}\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'from collections import '\n",
       "                                        'namedtuple\\\\\\\\n    divmod_output = '\n",
       "                                        \"namedtuple('Outputs', \"\n",
       "                                        \"['datapoints_training', \"\n",
       "                                        \"'datapoints_test', \"\n",
       "                                        \"'dataset_version'])\\\\\\\\n    return \"\n",
       "                                        '[float(x_train.shape[0]),float(x_test.shape[0]),dataset_version]\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-> str:\\\\\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\\\\\n        return '\n",
       "                                        'float_value\\\\\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"float.'.format(str(float_value), \"\n",
       "                                        'str(type(float_value))))\\\\\\\\n    '\n",
       "                                        'return str(float_value)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_str(str_value: str) -> '\n",
       "                                        'str:\\\\\\\\n    if not '\n",
       "                                        'isinstance(str_value, '\n",
       "                                        'str):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"str.'.format(str(str_value), \"\n",
       "                                        'str(type(str_value))))\\\\\\\\n    return '\n",
       "                                        'str_value\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Get \"\n",
       "                                        \"data batch', description='Function to \"\n",
       "                                        'get dataset and load it to minio '\n",
       "                                        'bucket\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=3)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'get_data_batch(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    _serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_str,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Get data batch\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"datapoints_training\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Float\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"datapoints_test\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Float\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"dataset_version\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}]}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\"}}}, {\"name\": \"get-latest-data\", '\n",
       "                                        '\"container\": {\"args\": [], \"command\": '\n",
       "                                        '[\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def get_latest_data():\\\\n    '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n    Dummy functions for '\n",
       "                                        'showcasing\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    '\n",
       "                                        'print(\\\\\"Adding latest '\n",
       "                                        'data\\\\\")\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Get \"\n",
       "                                        \"latest data', description='Dummy \"\n",
       "                                        'functions for '\n",
       "                                        \"showcasing')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'get_latest_data(**_parsed_args)\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\"}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"description\\\\\": \\\\\"Dummy '\n",
       "                                        'functions for showcasing\\\\\", '\n",
       "                                        '\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": [], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'get_latest_data():\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    Dummy '\n",
       "                                        'functions for showcasing\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'print(\\\\\\\\\\\\\"Adding latest '\n",
       "                                        'data\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Get \"\n",
       "                                        \"latest data', description='Dummy \"\n",
       "                                        'functions for '\n",
       "                                        \"showcasing')\\\\\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'get_latest_data(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Get latest data\\\\\"}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\"}}}, {\"name\": \"model-building\", '\n",
       "                                        '\"container\": {\"args\": [\"--no-epochs\", '\n",
       "                                        '\"1\", \"--optimizer\", \"adam\", '\n",
       "                                        '\"----output-paths\", '\n",
       "                                        '\"/tmp/outputs/mlpipeline_ui_metadata/data\", '\n",
       "                                        '\"/tmp/outputs/mlpipeline_metrics/data\"], '\n",
       "                                        '\"command\": [\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def model_building(\\\\n    no_epochs '\n",
       "                                        '= 1,\\\\n    optimizer = '\n",
       "                                        '\\\\\"adam\\\\\"\\\\n):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    '\n",
       "                                        'Build the model with Keras API\\\\n    '\n",
       "                                        'Export model parameters\\\\n    '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n    from tensorflow '\n",
       "                                        'import keras\\\\n    import tensorflow '\n",
       "                                        'as tf\\\\n    from minio import '\n",
       "                                        'Minio\\\\n    import numpy as np\\\\n    '\n",
       "                                        'import pandas as pd\\\\n    import '\n",
       "                                        'json\\\\n    import os\\\\n\\\\n    '\n",
       "                                        'minio_client = Minio(\\\\n        '\n",
       "                                        '\\\\\"172.17.0.15:9000\\\\\",\\\\n        '\n",
       "                                        'access_key=\\\\\"minio\\\\\",\\\\n        '\n",
       "                                        'secret_key=\\\\\"minio123\\\\\",\\\\n        '\n",
       "                                        'secure=False\\\\n    )\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\"mlpipeline\\\\\"\\\\n\\\\n    model = '\n",
       "                                        'keras.models.Sequential()\\\\n    '\n",
       "                                        'model.add(keras.layers.Conv2D(64, (3, '\n",
       "                                        \"3), activation='relu', \"\n",
       "                                        'input_shape=(28,28,1)))\\\\n    '\n",
       "                                        'model.add(keras.layers.MaxPool2D(2, '\n",
       "                                        '2))\\\\n\\\\n    '\n",
       "                                        'model.add(keras.layers.Flatten())\\\\n    '\n",
       "                                        'model.add(keras.layers.Dense(64, '\n",
       "                                        \"activation='relu'))\\\\n\\\\n    \"\n",
       "                                        'model.add(keras.layers.Dense(32, '\n",
       "                                        \"activation='relu'))\\\\n\\\\n    \"\n",
       "                                        'model.add(keras.layers.Dense(10, '\n",
       "                                        \"activation='softmax')) #output are 10 \"\n",
       "                                        'classes, numbers from 0-9\\\\n\\\\n    '\n",
       "                                        '#show model summary - how it '\n",
       "                                        'looks\\\\n    stringlist = []\\\\n    '\n",
       "                                        'model.summary(print_fn=lambda x: '\n",
       "                                        'stringlist.append(x))\\\\n    '\n",
       "                                        'metric_model_summary = '\n",
       "                                        '\\\\\"\\\\\\\\n\\\\\".join(stringlist)\\\\n\\\\n    '\n",
       "                                        '#compile the model - we want to have '\n",
       "                                        'a binary outcome\\\\n    '\n",
       "                                        'model.compile(optimizer=optimizer,\\\\n              '\n",
       "                                        'loss=\\\\\"sparse_categorical_crossentropy\\\\\",\\\\n              '\n",
       "                                        \"metrics=['accuracy'])\\\\n\\\\n    if not \"\n",
       "                                        'os.path.exists(\\\\\"./tmp\\\\\"):\\\\n        '\n",
       "                                        'os.makedirs(\\\\\"./tmp\\\\\")\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"x_train\\\\\",\\\\\"./tmp/x_train.npy\\\\\")\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'np.load(\\\\\"./tmp/x_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"y_train\\\\\",\\\\\"./tmp/y_train.npy\\\\\")\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'np.load(\\\\\"./tmp/y_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        '#fit the model and return the history '\n",
       "                                        'while training\\\\n    history = '\n",
       "                                        'model.fit(\\\\n      x=x_train,\\\\n      '\n",
       "                                        'y=y_train,\\\\n      '\n",
       "                                        'epochs=no_epochs,\\\\n      '\n",
       "                                        'batch_size=20,\\\\n    )\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"x_test\\\\\",\\\\\"./tmp/x_test.npy\\\\\")\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'np.load(\\\\\"./tmp/x_test.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"y_test\\\\\",\\\\\"./tmp/y_test.npy\\\\\")\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'np.load(\\\\\"./tmp/y_test.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        '# Test the model against the test '\n",
       "                                        'dataset\\\\n    # Returns the loss '\n",
       "                                        'value & metrics values for the model '\n",
       "                                        'in test mode.\\\\n    model_loss, '\n",
       "                                        'model_accuracy = '\n",
       "                                        'model.evaluate(x=x_test,y=y_test)\\\\n\\\\n    '\n",
       "                                        '# Confusion Matrix\\\\n\\\\n    # '\n",
       "                                        'Generates output predictions for the '\n",
       "                                        'input samples.\\\\n    test_predictions '\n",
       "                                        '= model.predict(x=x_test)\\\\n\\\\n    # '\n",
       "                                        'Returns the indices of the maximum '\n",
       "                                        'values along an axis.\\\\n    '\n",
       "                                        'test_predictions = '\n",
       "                                        'np.argmax(test_predictions,axis=1) # '\n",
       "                                        'the prediction outputs 10 values, we '\n",
       "                                        'take the index number of the highest '\n",
       "                                        'value, which is the prediction of the '\n",
       "                                        'model\\\\n\\\\n    # generate confusion '\n",
       "                                        'matrix\\\\n    confusion_matrix = '\n",
       "                                        'tf.math.confusion_matrix(labels=y_test,predictions=test_predictions)\\\\n    '\n",
       "                                        'confusion_matrix = '\n",
       "                                        'confusion_matrix.numpy()\\\\n    vocab '\n",
       "                                        '= list(np.unique(y_test))\\\\n    data '\n",
       "                                        '= []\\\\n    for target_index, '\n",
       "                                        'target_row in '\n",
       "                                        'enumerate(confusion_matrix):\\\\n        '\n",
       "                                        'for predicted_index, count in '\n",
       "                                        'enumerate(target_row):\\\\n            '\n",
       "                                        'data.append((vocab[target_index], '\n",
       "                                        'vocab[predicted_index], '\n",
       "                                        'count))\\\\n\\\\n    df_cm = '\n",
       "                                        \"pd.DataFrame(data, columns=['target', \"\n",
       "                                        \"'predicted', 'count'])\\\\n    cm_csv = \"\n",
       "                                        'df_cm.to_csv(header=False, '\n",
       "                                        'index=False)\\\\n\\\\n    metadata = '\n",
       "                                        '{\\\\n        \\\\\"outputs\\\\\": '\n",
       "                                        '[\\\\n            {\\\\n                '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"confusion_matrix\\\\\",\\\\n                '\n",
       "                                        '\\\\\"format\\\\\": '\n",
       "                                        '\\\\\"csv\\\\\",\\\\n                '\n",
       "                                        '\\\\\"schema\\\\\": [\\\\n                    '\n",
       "                                        \"{'name': 'target', 'type': \"\n",
       "                                        \"'CATEGORY'},\\\\n                    \"\n",
       "                                        \"{'name': 'predicted', 'type': \"\n",
       "                                        \"'CATEGORY'},\\\\n                    \"\n",
       "                                        \"{'name': 'count', 'type': \"\n",
       "                                        \"'NUMBER'},\\\\n                  \"\n",
       "                                        '],\\\\n                \\\\\"target_col\\\\\" '\n",
       "                                        ': \\\\\"actual\\\\\",\\\\n                '\n",
       "                                        '\\\\\"predicted_col\\\\\" : '\n",
       "                                        '\\\\\"predicted\\\\\",\\\\n                '\n",
       "                                        '\\\\\"source\\\\\": '\n",
       "                                        'cm_csv,\\\\n                '\n",
       "                                        '\\\\\"storage\\\\\": '\n",
       "                                        '\\\\\"inline\\\\\",\\\\n                '\n",
       "                                        '\\\\\"labels\\\\\": '\n",
       "                                        '[0,1,2,3,4,5,6,7,8,9]\\\\n            '\n",
       "                                        '},\\\\n            {\\\\n                '\n",
       "                                        \"'storage': \"\n",
       "                                        \"'inline',\\\\n                'source': \"\n",
       "                                        \"'''# Model Overview\\\\n## Model \"\n",
       "                                        'Summary\\\\n\\\\n```\\\\n{}\\\\n```\\\\n\\\\n## '\n",
       "                                        'Model Performance\\\\n\\\\n**Accuracy**: '\n",
       "                                        '{}\\\\n**Loss**: '\n",
       "                                        \"{}\\\\n\\\\n'''.format(metric_model_summary,model_accuracy,model_loss),\\\\n                \"\n",
       "                                        \"'type': 'markdown',\\\\n            \"\n",
       "                                        '}\\\\n        ]\\\\n    }\\\\n\\\\n    '\n",
       "                                        \"metrics = {\\\\n      'metrics': \"\n",
       "                                        \"[{\\\\n          'name': \"\n",
       "                                        \"'model_accuracy',\\\\n          \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'float(model_accuracy),\\\\n          '\n",
       "                                        \"'format' : \"\n",
       "                                        '\\\\\"PERCENTAGE\\\\\"\\\\n        '\n",
       "                                        \"},{\\\\n          'name': \"\n",
       "                                        \"'model_loss',\\\\n          \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'float(model_loss),\\\\n          '\n",
       "                                        \"'format' : \"\n",
       "                                        '\\\\\"PERCENTAGE\\\\\"\\\\n        '\n",
       "                                        '}]}\\\\n\\\\n    ### Save model to '\n",
       "                                        'minIO\\\\n\\\\n    if not '\n",
       "                                        'os.path.exists(\\\\\"./models\\\\\"):\\\\n        '\n",
       "                                        'os.makedirs(\\\\\"./models\\\\\")\\\\n\\\\n    '\n",
       "                                        'keras.models.save_model(model,\\\\\"./models/detect-digits\\\\\")\\\\n\\\\n    '\n",
       "                                        'from minio import Minio\\\\n    import '\n",
       "                                        'os\\\\n\\\\n    minio_client = '\n",
       "                                        'Minio(\\\\n            '\n",
       "                                        '\\\\\"172.17.0.15:9000\\\\\",\\\\n            '\n",
       "                                        'access_key=\\\\\"minio\\\\\",\\\\n            '\n",
       "                                        'secret_key=\\\\\"minio123\\\\\",\\\\n            '\n",
       "                                        'secure=False\\\\n        )\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\"mlpipeline\\\\\"\\\\n\\\\n    import '\n",
       "                                        'glob\\\\n\\\\n    def '\n",
       "                                        'upload_local_directory_to_minio(local_path, '\n",
       "                                        'bucket_name, minio_path):\\\\n        '\n",
       "                                        'assert '\n",
       "                                        'os.path.isdir(local_path)\\\\n\\\\n        '\n",
       "                                        'for local_file in '\n",
       "                                        'glob.glob(local_path + '\n",
       "                                        \"'/**'):\\\\n            local_file = \"\n",
       "                                        'local_file.replace(os.sep, \\\\\"/\\\\\") # '\n",
       "                                        'Replace \\\\\\\\ with / on '\n",
       "                                        'Windows\\\\n            if not '\n",
       "                                        'os.path.isfile(local_file):\\\\n                '\n",
       "                                        'upload_local_directory_to_minio(\\\\n                    '\n",
       "                                        'local_file, bucket_name, minio_path + '\n",
       "                                        '\\\\\"/\\\\\" + '\n",
       "                                        'os.path.basename(local_file))\\\\n            '\n",
       "                                        'else:\\\\n                remote_path = '\n",
       "                                        'os.path.join(\\\\n                    '\n",
       "                                        'minio_path, local_file[1 + '\n",
       "                                        'len(local_path):])\\\\n                '\n",
       "                                        'remote_path = '\n",
       "                                        'remote_path.replace(\\\\n                    '\n",
       "                                        'os.sep, \\\\\"/\\\\\")  # Replace \\\\\\\\ with '\n",
       "                                        '/ on Windows\\\\n                '\n",
       "                                        'minio_client.fput_object(bucket_name, '\n",
       "                                        'remote_path, local_file)\\\\n\\\\n    '\n",
       "                                        'upload_local_directory_to_minio(\\\\\"./models/detect-digits\\\\\",minio_bucket,\\\\\"models/detect-digits/1/\\\\\") '\n",
       "                                        '# 1 for version 1\\\\n\\\\n    '\n",
       "                                        'print(\\\\\"Saved model to '\n",
       "                                        'minIO\\\\\")\\\\n\\\\n    from collections '\n",
       "                                        'import namedtuple\\\\n    output = '\n",
       "                                        \"namedtuple('output', \"\n",
       "                                        \"['mlpipeline_ui_metadata', \"\n",
       "                                        \"'mlpipeline_metrics'])\\\\n    return \"\n",
       "                                        'output(json.dumps(metadata),json.dumps(metrics))\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Model \"\n",
       "                                        \"building', description='Build the \"\n",
       "                                        'model with Keras '\n",
       "                                        'API\\')\\\\n_parser.add_argument(\\\\\"--no-epochs\\\\\", '\n",
       "                                        'dest=\\\\\"no_epochs\\\\\", type=int, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--optimizer\\\\\", '\n",
       "                                        'dest=\\\\\"optimizer\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=2)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'model_building(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    str,\\\\n    '\n",
       "                                        'str,\\\\n\\\\n]\\\\n\\\\nimport os\\\\nfor idx, '\n",
       "                                        'output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\"}, '\n",
       "                                        '\"outputs\": {\"artifacts\": [{\"name\": '\n",
       "                                        '\"mlpipeline-ui-metadata\", \"path\": '\n",
       "                                        '\"/tmp/outputs/mlpipeline_ui_metadata/data\"}, '\n",
       "                                        '{\"name\": \"mlpipeline-metrics\", '\n",
       "                                        '\"path\": '\n",
       "                                        '\"/tmp/outputs/mlpipeline_metrics/data\"}]}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"description\\\\\": \\\\\"Build the '\n",
       "                                        'model with Keras API\\\\\", '\n",
       "                                        '\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[{\\\\\"if\\\\\": {\\\\\"cond\\\\\": '\n",
       "                                        '{\\\\\"isPresent\\\\\": \\\\\"no_epochs\\\\\"}, '\n",
       "                                        '\\\\\"then\\\\\": [\\\\\"--no-epochs\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"no_epochs\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"optimizer\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--optimizer\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"optimizer\\\\\"}]}}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_metrics\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'model_building(\\\\\\\\n    no_epochs = '\n",
       "                                        '1,\\\\\\\\n    optimizer = '\n",
       "                                        '\\\\\\\\\\\\\"adam\\\\\\\\\\\\\"\\\\\\\\n):\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    Build '\n",
       "                                        'the model with Keras API\\\\\\\\n    '\n",
       "                                        'Export model parameters\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    from '\n",
       "                                        'tensorflow import keras\\\\\\\\n    '\n",
       "                                        'import tensorflow as tf\\\\\\\\n    from '\n",
       "                                        'minio import Minio\\\\\\\\n    import '\n",
       "                                        'numpy as np\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import json\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n\\\\\\\\n    minio_client = '\n",
       "                                        'Minio(\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"172.17.0.15:9000\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'access_key=\\\\\\\\\\\\\"minio\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secret_key=\\\\\\\\\\\\\"minio123\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secure=False\\\\\\\\n    )\\\\\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\\\\\\\\\"mlpipeline\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'model = '\n",
       "                                        'keras.models.Sequential()\\\\\\\\n    '\n",
       "                                        'model.add(keras.layers.Conv2D(64, (3, '\n",
       "                                        \"3), activation='relu', \"\n",
       "                                        'input_shape=(28,28,1)))\\\\\\\\n    '\n",
       "                                        'model.add(keras.layers.MaxPool2D(2, '\n",
       "                                        '2))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'model.add(keras.layers.Flatten())\\\\\\\\n    '\n",
       "                                        'model.add(keras.layers.Dense(64, '\n",
       "                                        \"activation='relu'))\\\\\\\\n\\\\\\\\n    \"\n",
       "                                        'model.add(keras.layers.Dense(32, '\n",
       "                                        \"activation='relu'))\\\\\\\\n\\\\\\\\n    \"\n",
       "                                        'model.add(keras.layers.Dense(10, '\n",
       "                                        \"activation='softmax')) #output are 10 \"\n",
       "                                        'classes, numbers from '\n",
       "                                        '0-9\\\\\\\\n\\\\\\\\n    #show model summary '\n",
       "                                        '- how it looks\\\\\\\\n    stringlist = '\n",
       "                                        '[]\\\\\\\\n    '\n",
       "                                        'model.summary(print_fn=lambda x: '\n",
       "                                        'stringlist.append(x))\\\\\\\\n    '\n",
       "                                        'metric_model_summary = '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\".join(stringlist)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '#compile the model - we want to have '\n",
       "                                        'a binary outcome\\\\\\\\n    '\n",
       "                                        'model.compile(optimizer=optimizer,\\\\\\\\n              '\n",
       "                                        'loss=\\\\\\\\\\\\\"sparse_categorical_crossentropy\\\\\\\\\\\\\",\\\\\\\\n              '\n",
       "                                        \"metrics=['accuracy'])\\\\\\\\n\\\\\\\\n    if \"\n",
       "                                        'not '\n",
       "                                        'os.path.exists(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\"):\\\\\\\\n        '\n",
       "                                        'os.makedirs(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"x_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"y_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/y_train.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/y_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '#fit the model and return the history '\n",
       "                                        'while training\\\\\\\\n    history = '\n",
       "                                        'model.fit(\\\\\\\\n      '\n",
       "                                        'x=x_train,\\\\\\\\n      '\n",
       "                                        'y=y_train,\\\\\\\\n      '\n",
       "                                        'epochs=no_epochs,\\\\\\\\n      '\n",
       "                                        'batch_size=20,\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"x_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"y_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/y_test.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/y_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Test the model against the test '\n",
       "                                        'dataset\\\\\\\\n    # Returns the loss '\n",
       "                                        'value & metrics values for the model '\n",
       "                                        'in test mode.\\\\\\\\n    model_loss, '\n",
       "                                        'model_accuracy = '\n",
       "                                        'model.evaluate(x=x_test,y=y_test)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Confusion Matrix\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Generates output predictions for the '\n",
       "                                        'input samples.\\\\\\\\n    '\n",
       "                                        'test_predictions = '\n",
       "                                        'model.predict(x=x_test)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Returns the indices of the maximum '\n",
       "                                        'values along an axis.\\\\\\\\n    '\n",
       "                                        'test_predictions = '\n",
       "                                        'np.argmax(test_predictions,axis=1) # '\n",
       "                                        'the prediction outputs 10 values, we '\n",
       "                                        'take the index number of the highest '\n",
       "                                        'value, which is the prediction of the '\n",
       "                                        'model\\\\\\\\n\\\\\\\\n    # generate '\n",
       "                                        'confusion matrix\\\\\\\\n    '\n",
       "                                        'confusion_matrix = '\n",
       "                                        'tf.math.confusion_matrix(labels=y_test,predictions=test_predictions)\\\\\\\\n    '\n",
       "                                        'confusion_matrix = '\n",
       "                                        'confusion_matrix.numpy()\\\\\\\\n    '\n",
       "                                        'vocab = '\n",
       "                                        'list(np.unique(y_test))\\\\\\\\n    data '\n",
       "                                        '= []\\\\\\\\n    for target_index, '\n",
       "                                        'target_row in '\n",
       "                                        'enumerate(confusion_matrix):\\\\\\\\n        '\n",
       "                                        'for predicted_index, count in '\n",
       "                                        'enumerate(target_row):\\\\\\\\n            '\n",
       "                                        'data.append((vocab[target_index], '\n",
       "                                        'vocab[predicted_index], '\n",
       "                                        'count))\\\\\\\\n\\\\\\\\n    df_cm = '\n",
       "                                        \"pd.DataFrame(data, columns=['target', \"\n",
       "                                        \"'predicted', 'count'])\\\\\\\\n    cm_csv \"\n",
       "                                        '= df_cm.to_csv(header=False, '\n",
       "                                        'index=False)\\\\\\\\n\\\\\\\\n    metadata = '\n",
       "                                        '{\\\\\\\\n        \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": '\n",
       "                                        '[\\\\\\\\n            '\n",
       "                                        '{\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"type\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"confusion_matrix\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"format\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"csv\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"schema\\\\\\\\\\\\\": '\n",
       "                                        \"[\\\\\\\\n                    {'name': \"\n",
       "                                        \"'target', 'type': \"\n",
       "                                        \"'CATEGORY'},\\\\\\\\n                    \"\n",
       "                                        \"{'name': 'predicted', 'type': \"\n",
       "                                        \"'CATEGORY'},\\\\\\\\n                    \"\n",
       "                                        \"{'name': 'count', 'type': \"\n",
       "                                        \"'NUMBER'},\\\\\\\\n                  \"\n",
       "                                        '],\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"target_col\\\\\\\\\\\\\" : '\n",
       "                                        '\\\\\\\\\\\\\"actual\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"predicted_col\\\\\\\\\\\\\" : '\n",
       "                                        '\\\\\\\\\\\\\"predicted\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"source\\\\\\\\\\\\\": '\n",
       "                                        'cm_csv,\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"storage\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"inline\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"labels\\\\\\\\\\\\\": '\n",
       "                                        '[0,1,2,3,4,5,6,7,8,9]\\\\\\\\n            '\n",
       "                                        '},\\\\\\\\n            '\n",
       "                                        \"{\\\\\\\\n                'storage': \"\n",
       "                                        \"'inline',\\\\\\\\n                \"\n",
       "                                        \"'source': '''# Model Overview\\\\\\\\n## \"\n",
       "                                        'Model '\n",
       "                                        'Summary\\\\\\\\n\\\\\\\\n```\\\\\\\\n{}\\\\\\\\n```\\\\\\\\n\\\\\\\\n## '\n",
       "                                        'Model '\n",
       "                                        'Performance\\\\\\\\n\\\\\\\\n**Accuracy**: '\n",
       "                                        '{}\\\\\\\\n**Loss**: '\n",
       "                                        \"{}\\\\\\\\n\\\\\\\\n'''.format(metric_model_summary,model_accuracy,model_loss),\\\\\\\\n                \"\n",
       "                                        \"'type': 'markdown',\\\\\\\\n            \"\n",
       "                                        '}\\\\\\\\n        ]\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n\\\\\\\\n    metrics = {\\\\\\\\n      '\n",
       "                                        \"'metrics': [{\\\\\\\\n          'name': \"\n",
       "                                        \"'model_accuracy',\\\\\\\\n          \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'float(model_accuracy),\\\\\\\\n          '\n",
       "                                        \"'format' : \"\n",
       "                                        '\\\\\\\\\\\\\"PERCENTAGE\\\\\\\\\\\\\"\\\\\\\\n        '\n",
       "                                        \"},{\\\\\\\\n          'name': \"\n",
       "                                        \"'model_loss',\\\\\\\\n          \"\n",
       "                                        \"'numberValue':  \"\n",
       "                                        'float(model_loss),\\\\\\\\n          '\n",
       "                                        \"'format' : \"\n",
       "                                        '\\\\\\\\\\\\\"PERCENTAGE\\\\\\\\\\\\\"\\\\\\\\n        '\n",
       "                                        '}]}\\\\\\\\n\\\\\\\\n    ### Save model to '\n",
       "                                        'minIO\\\\\\\\n\\\\\\\\n    if not '\n",
       "                                        'os.path.exists(\\\\\\\\\\\\\"./models\\\\\\\\\\\\\"):\\\\\\\\n        '\n",
       "                                        'os.makedirs(\\\\\\\\\\\\\"./models\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'keras.models.save_model(model,\\\\\\\\\\\\\"./models/detect-digits\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'from minio import Minio\\\\\\\\n    '\n",
       "                                        'import os\\\\\\\\n\\\\\\\\n    minio_client = '\n",
       "                                        'Minio(\\\\\\\\n            '\n",
       "                                        '\\\\\\\\\\\\\"172.17.0.15:9000\\\\\\\\\\\\\",\\\\\\\\n            '\n",
       "                                        'access_key=\\\\\\\\\\\\\"minio\\\\\\\\\\\\\",\\\\\\\\n            '\n",
       "                                        'secret_key=\\\\\\\\\\\\\"minio123\\\\\\\\\\\\\",\\\\\\\\n            '\n",
       "                                        'secure=False\\\\\\\\n        )\\\\\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\\\\\\\\\"mlpipeline\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'import glob\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'upload_local_directory_to_minio(local_path, '\n",
       "                                        'bucket_name, minio_path):\\\\\\\\n        '\n",
       "                                        'assert '\n",
       "                                        'os.path.isdir(local_path)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'for local_file in '\n",
       "                                        'glob.glob(local_path + '\n",
       "                                        \"'/**'):\\\\\\\\n            local_file = \"\n",
       "                                        'local_file.replace(os.sep, '\n",
       "                                        '\\\\\\\\\\\\\"/\\\\\\\\\\\\\") # Replace \\\\\\\\\\\\\\\\ '\n",
       "                                        'with / on Windows\\\\\\\\n            if '\n",
       "                                        'not '\n",
       "                                        'os.path.isfile(local_file):\\\\\\\\n                '\n",
       "                                        'upload_local_directory_to_minio(\\\\\\\\n                    '\n",
       "                                        'local_file, bucket_name, minio_path + '\n",
       "                                        '\\\\\\\\\\\\\"/\\\\\\\\\\\\\" + '\n",
       "                                        'os.path.basename(local_file))\\\\\\\\n            '\n",
       "                                        'else:\\\\\\\\n                remote_path '\n",
       "                                        '= '\n",
       "                                        'os.path.join(\\\\\\\\n                    '\n",
       "                                        'minio_path, local_file[1 + '\n",
       "                                        'len(local_path):])\\\\\\\\n                '\n",
       "                                        'remote_path = '\n",
       "                                        'remote_path.replace(\\\\\\\\n                    '\n",
       "                                        'os.sep, \\\\\\\\\\\\\"/\\\\\\\\\\\\\")  # Replace '\n",
       "                                        '\\\\\\\\\\\\\\\\ with / on '\n",
       "                                        'Windows\\\\\\\\n                '\n",
       "                                        'minio_client.fput_object(bucket_name, '\n",
       "                                        'remote_path, local_file)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'upload_local_directory_to_minio(\\\\\\\\\\\\\"./models/detect-digits\\\\\\\\\\\\\",minio_bucket,\\\\\\\\\\\\\"models/detect-digits/1/\\\\\\\\\\\\\") '\n",
       "                                        '# 1 for version 1\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'print(\\\\\\\\\\\\\"Saved model to '\n",
       "                                        'minIO\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    from '\n",
       "                                        'collections import namedtuple\\\\\\\\n    '\n",
       "                                        \"output = namedtuple('output', \"\n",
       "                                        \"['mlpipeline_ui_metadata', \"\n",
       "                                        \"'mlpipeline_metrics'])\\\\\\\\n    return \"\n",
       "                                        'output(json.dumps(metadata),json.dumps(metrics))\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Model \"\n",
       "                                        \"building', description='Build the \"\n",
       "                                        'model with Keras '\n",
       "                                        'API\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--no-epochs\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"no_epochs\\\\\\\\\\\\\", '\n",
       "                                        'type=int, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--optimizer\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"optimizer\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=2)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'model_building(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    str,\\\\\\\\n    '\n",
       "                                        'str,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"1\\\\\", \\\\\"name\\\\\": \\\\\"no_epochs\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Integer\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"adam\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"optimizer\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Model building\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"UI_metadata\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_metrics\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Metrics\\\\\"}]}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\", '\n",
       "                                        '\"pipelines.kubeflow.org/arguments.parameters\": '\n",
       "                                        '\"{\\\\\"no_epochs\\\\\": \\\\\"1\\\\\", '\n",
       "                                        '\\\\\"optimizer\\\\\": \\\\\"adam\\\\\"}\"}}}, '\n",
       "                                        '{\"name\": \"reshape-data\", \"container\": '\n",
       "                                        '{\"args\": [], \"command\": [\"sh\", \"-ec\", '\n",
       "                                        '\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" > '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\", '\n",
       "                                        '\"def reshape_data():\\\\n    '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n    Reshape the data for '\n",
       "                                        'model building\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    '\n",
       "                                        'print(\\\\\"reshaping data\\\\\")\\\\n\\\\n    '\n",
       "                                        'from minio import Minio\\\\n    import '\n",
       "                                        'numpy as np\\\\n    import os\\\\n\\\\n    '\n",
       "                                        'minio_client = Minio(\\\\n        '\n",
       "                                        '\\\\\"172.17.0.15:9000\\\\\",\\\\n        '\n",
       "                                        'access_key=\\\\\"minio\\\\\",\\\\n        '\n",
       "                                        'secret_key=\\\\\"minio123\\\\\",\\\\n        '\n",
       "                                        'secure=False\\\\n    )\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\"mlpipeline\\\\\"\\\\n\\\\n    if not '\n",
       "                                        'os.path.exists(\\\\\"./tmp\\\\\"):\\\\n        '\n",
       "                                        'os.makedirs(\\\\\"./tmp\\\\\")\\\\n\\\\n    # '\n",
       "                                        'load data from minio\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"x_train\\\\\",\\\\\"./tmp/x_train.npy\\\\\")\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'np.load(\\\\\"./tmp/x_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\"x_test\\\\\",\\\\\"./tmp/x_test.npy\\\\\")\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'np.load(\\\\\"./tmp/x_test.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        '# reshaping the data\\\\n    # '\n",
       "                                        'reshaping pixels in a 28x28px image '\n",
       "                                        'with greyscale, canal = 1. This is '\n",
       "                                        'needed for the Keras API\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'x_train.reshape(-1,28,28,1)\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'x_test.reshape(-1,28,28,1)\\\\n\\\\n    # '\n",
       "                                        'normalizing the data\\\\n    # each '\n",
       "                                        'pixel has a value between 0-255. Here '\n",
       "                                        'we divide by 255, to get values from '\n",
       "                                        '0-1\\\\n    x_train = x_train / '\n",
       "                                        '255\\\\n    x_test = x_test / '\n",
       "                                        '255\\\\n\\\\n    # save data from '\n",
       "                                        'minio\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/x_train.npy\\\\\",x_train)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"x_train\\\\\",\\\\\"./tmp/x_train.npy\\\\\")\\\\n\\\\n    '\n",
       "                                        'np.save(\\\\\"./tmp/x_test.npy\\\\\",x_test)\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\"x_test\\\\\",\\\\\"./tmp/x_test.npy\\\\\")\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Reshape \"\n",
       "                                        \"data', description='Reshape the data \"\n",
       "                                        \"for model building')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= reshape_data(**_parsed_args)\\\\n\"], '\n",
       "                                        '\"image\": '\n",
       "                                        '\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\"}, '\n",
       "                                        '\"metadata\": {\"labels\": '\n",
       "                                        '{\"pipelines.kubeflow.org/kfp_sdk_version\": '\n",
       "                                        '\"1.6.3\", '\n",
       "                                        '\"pipelines.kubeflow.org/pipeline-sdk-type\": '\n",
       "                                        '\"kfp\"}, \"annotations\": '\n",
       "                                        '{\"pipelines.kubeflow.org/component_spec\": '\n",
       "                                        '\"{\\\\\"description\\\\\": \\\\\"Reshape the '\n",
       "                                        'data for model building\\\\\", '\n",
       "                                        '\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": [], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" > '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'reshape_data():\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    Reshape '\n",
       "                                        'the data for model building\\\\\\\\n    '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'print(\\\\\\\\\\\\\"reshaping '\n",
       "                                        'data\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    from minio '\n",
       "                                        'import Minio\\\\\\\\n    import numpy as '\n",
       "                                        'np\\\\\\\\n    import os\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client = Minio(\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"172.17.0.15:9000\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'access_key=\\\\\\\\\\\\\"minio\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secret_key=\\\\\\\\\\\\\"minio123\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        'secure=False\\\\\\\\n    )\\\\\\\\n    '\n",
       "                                        'minio_bucket = '\n",
       "                                        '\\\\\\\\\\\\\"mlpipeline\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'if not '\n",
       "                                        'os.path.exists(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\"):\\\\\\\\n        '\n",
       "                                        'os.makedirs(\\\\\\\\\\\\\"./tmp\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# load data from minio\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"x_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'minio_client.fget_object(minio_bucket,\\\\\\\\\\\\\"x_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'np.load(\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# reshaping the data\\\\\\\\n    # '\n",
       "                                        'reshaping pixels in a 28x28px image '\n",
       "                                        'with greyscale, canal = 1. This is '\n",
       "                                        'needed for the Keras API\\\\\\\\n    '\n",
       "                                        'x_train = '\n",
       "                                        'x_train.reshape(-1,28,28,1)\\\\\\\\n    '\n",
       "                                        'x_test = '\n",
       "                                        'x_test.reshape(-1,28,28,1)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# normalizing the data\\\\\\\\n    # each '\n",
       "                                        'pixel has a value between 0-255. Here '\n",
       "                                        'we divide by 255, to get values from '\n",
       "                                        '0-1\\\\\\\\n    x_train = x_train / '\n",
       "                                        '255\\\\\\\\n    x_test = x_test / '\n",
       "                                        '255\\\\\\\\n\\\\\\\\n    # save data from '\n",
       "                                        'minio\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\",x_train)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"x_train\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_train.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'np.save(\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\",x_test)\\\\\\\\n    '\n",
       "                                        'minio_client.fput_object(minio_bucket,\\\\\\\\\\\\\"x_test\\\\\\\\\\\\\",\\\\\\\\\\\\\"./tmp/x_test.npy\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Reshape \"\n",
       "                                        \"data', description='Reshape the data \"\n",
       "                                        \"for model building')\\\\\\\\n_parsed_args \"\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'reshape_data(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0\\\\\"}}, '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Reshape data\\\\\"}\", '\n",
       "                                        '\"pipelines.kubeflow.org/component_ref\": '\n",
       "                                        '\"{}\"}}}], \"arguments\": {\"parameters\": '\n",
       "                                        '[{\"name\": \"no_epochs\"}, {\"name\": '\n",
       "                                        '\"optimizer\"}]}, \"serviceAccountName\": '\n",
       "                                        '\"pipeline-runner\"}}'},\n",
       " 'resource_references': [{'key': {'id': 'a536241d-4a75-44e7-8060-3b72d615ce88',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'mnist-pipeline',\n",
       "                          'relationship': 'OWNER'}],\n",
       " 'scheduled_at': datetime.datetime(2023, 1, 1, 9, 26, 31, tzinfo=tzlocal()),\n",
       " 'service_account': 'default-editor',\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run_pipeline(experiment_id=experiment.id,job_name=pipeline_name,pipeline_package_path=pipeline_package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513994c1-e1fa-4a80-ab1d-a3356aa33286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f0445214270c57c59a705a6eaadb196f0a3868836f70703f34ac88d1617f8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
